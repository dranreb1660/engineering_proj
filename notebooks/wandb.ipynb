{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from fpl_engineering.data.lit_data_module import FPLDataModule\n",
    "from fpl_engineering.models.lit_models import FPLLSTMRegressor\n",
    "\n",
    "from fpl_engineering.utils import get_project_root\n",
    "project_root = str(get_project_root())\n",
    "log_dir = project_root+'/logs'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sweep_config = {\n",
    "  \"method\": \"random\",   # random search\n",
    "  \"metric\": {           # We want to maximize val_accuracy\n",
    "      \"name\": \"val_loss\",\n",
    "      \"goal\": \"minimize\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "        \"dropout\": {\n",
    "            # Choose from pre-defined values\n",
    "            \"values\": [0.3, 0.4, 0.5, 0.75, 0.85]\n",
    "        },\n",
    "        \"hidden_size\": {\n",
    "            # Choose from pre-defined values\n",
    "            \"values\": [64, 128, 256, 512]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            # Choose from pre-defined values\n",
    "            \"values\": [64, 128, 256, 512]\n",
    "        },\n",
    "        \"lr\": {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 0.1\n",
    "        },\n",
    "        \"seq_len\": {\n",
    "            # Choose from pre-defined values\n",
    "            \"values\": [4,5] \n",
    "        },\n",
    "        \"n_layers\": {\n",
    "            # Choose from pre-defined values\n",
    "            \"values\": [1,2] \n",
    "        }\n",
    "    },\n",
    "'early_terminate' :{\n",
    "    'type': 'hyperband',\n",
    "    's': 2,\n",
    "    'eta': 3,\n",
    "    'max_iter': 40\n",
    "}\n",
    "}\n",
    "\n",
    "static_config = {'n_features': 35, 'epochs':40}\n",
    "\n",
    "def sweep_iteration():\n",
    "\n",
    "    # set up W&B logger\n",
    "    wandb.init(config=sweep_config)    # required to have access to `wandb.config`\n",
    "    config = wandb.config\n",
    "\n",
    "    # setup data\n",
    "    data_module = FPLDataModule(batch_size=config.batch_size, seq_len=config.seq_len, download_data=False)\n",
    "\n",
    "\n",
    "    # setup model - note how we refer to sweep parameters with wandb.config\n",
    "    model = FPLLSTMRegressor(n_features= static_config['n_features'], hidden_size=config.hidden_size, seq_len=config.seq_len, \n",
    "                            batch_size=config.batch_size, num_layers=config.n_layers, dropout=config.dropout,learning_rate=config.lr)\n",
    "\n",
    "\n",
    "    # early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4, verbose=True)\n",
    "    progress_bar = TQDMProgressBar(refresh_rate=1)\n",
    "\n",
    "    logger = WandbLogger(save_dir=log_dir, project='FPL')\n",
    "    callbacks = [progress_bar]\n",
    "\n",
    "    # setup Trainer\n",
    "    trainer = pl.Trainer(accelerator = device,\n",
    "                        max_epochs = static_config['epochs'],\n",
    "                        logger= logger,\n",
    "                        callbacks = callbacks,\n",
    "                        log_every_n_steps=20,\n",
    "                        precision=16)\n",
    "\n",
    "    # train\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    '''\n",
    "    All parameters are aggregated in one place.\n",
    "    This is useful for reporting experiment params to experiment tracking software\n",
    "    '''\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"FPL\")\n",
    "    wandb.agent(sweep_id, sweep_iteration,project='FPL' ,count=100)\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fpl_engineering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2e192230af1b475cc0711ce02536036f1b42d1e6f068a8b8676df20d95c97b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
